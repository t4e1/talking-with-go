// readme
# Speaking Helper
## Outline
- `purpose:` Toy project using Go + C + LLM services.
- `simple architecture:` Simple Client + Web Application + Monitoring 
- `skills:` Go, C(eBPF), AWS(or other cloud services?), promstack, postgresql, and so on...
- `theme:` When the speaker choose specific topic of conversation and talks about it, LLM returns appropriate answer to the Speaker. 
- `predicted Workflow:` Speaker > (voice to text) > ollama(or ?) > (text to voice) > Speaker 

## 